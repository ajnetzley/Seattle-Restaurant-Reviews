{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alex Netzley\n",
    "#2/18/2024\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the new google dataset\n",
    "data_folder = os.path.join(os.path.dirname(os.getcwd())+'/data/')\n",
    "#Read in google Data\n",
    "yelp_data_raw = pd.read_csv(os.path.join(data_folder, 'yelp_final.csv'))\n",
    "trip_advisor_data_raw = pd.read_csv(os.path.join(data_folder, 'trip_advisor_full.csv'))\n",
    "google_data_raw = pd.read_csv(os.path.join(data_folder, 'google_full.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood(df):\n",
    "    neighborhood_zipcode = {}\n",
    "    zipcode = ['98101', '98102', '98103', '98104', '98105', '98107', '98109', '98112', '98121', '98122', '98125', '98133']\n",
    "    neighborhood = ['Downtown', 'Capitol Hill', 'Fremont/Wallingford', 'Chinatown', 'University District', 'Ballard', 'Queen Anne/South Lake Union', 'Capitol Hill', 'Belltown', 'Capitol Hill', 'Northgate', 'Bitter Lake']\n",
    "    for i in range(len(zipcode)):\n",
    "        neighborhood_zipcode[zipcode[i]] = neighborhood[i]\n",
    "    df['Neighborhood'] = 'Other'\n",
    "    df['Neighborhood'] = df['Zip Code'].map(neighborhood_zipcode).fillna(df['Neighborhood'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Yelp Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all rows without ratings\n",
    "yelp_data = yelp_data_raw[yelp_data_raw['Yelp Rating'].notna()]\n",
    "yelp_data = yelp_data_raw[yelp_data_raw['Yelp Num Reviews'].notna()]\n",
    "\n",
    "#Drop irrelevant Columns\n",
    "yelp_data = yelp_data.drop(columns=['Yelp URL', 'Yelp Name'])\n",
    "\n",
    "#Rename columns to fit naming convention\n",
    "yelp_data = yelp_data.rename(columns={'Restaurant':'Name', \n",
    "                                              'Yelp Rating':'Rating',\n",
    "                                              'Yelp Num Reviews':'Num Reviews',\n",
    "                                              'Yelp Cost':'Cost',\n",
    "                                              'Yelp Tags':'Tags',\n",
    "                                              'Yelp Distribution':'Distribution'  })\n",
    "\n",
    "#Drop (near) Duplicate entries\n",
    "yelp_data[\"add_beg\"] = yelp_data['Address'].str.strip().str[:5]\n",
    "yelp_data[\"name_beg\"] = yelp_data['Name'].str.strip().str[:5]\n",
    "yelp_data = yelp_data.drop_duplicates(subset = ['name_beg', 'add_beg'])\n",
    "yelp_data = yelp_data.drop(columns=['add_beg', 'name_beg'])\n",
    "\n",
    "#Drop entries that are not from Seattle\n",
    "yelp_data = yelp_data[yelp_data['Address'].str.contains(\"Seattle\", na=False)]\n",
    "yelp_data[\"Zip Code\"] = yelp_data['Address'].str.strip().str.extract(r'(\\b981\\d{2}\\b)')\n",
    "\n",
    "yelp_data = get_neighborhood(yelp_data)\n",
    "\n",
    "#Export to csv\n",
    "yelp_data.to_csv(os.path.join(data_folder, 'Yelp_Processed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Trip Advisor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all rows without ratings\n",
    "trip_advisor_data = trip_advisor_data_raw[trip_advisor_data_raw['Rating'].notna()]\n",
    "trip_advisor_data = trip_advisor_data_raw[trip_advisor_data_raw['Number_of_reviews'].notna()]\n",
    "\n",
    "#Drop irrelevant Columns\n",
    "trip_advisor_data = trip_advisor_data.drop(columns=['URL'])\n",
    "\n",
    "#Rename columns to fit naming convention\n",
    "trip_advisor_data = trip_advisor_data.rename(columns={'Restaurant':'Name', \n",
    "                                              'Number_of_reviews':'Num Reviews',\n",
    "                                              'DollarSigns':'Cost',\n",
    "                                              'RestaurantType':'Tags' })\n",
    "\n",
    "#Drop (near) Duplicate entries\n",
    "trip_advisor_data[\"add_beg\"] = trip_advisor_data['Address'].str.strip().str[:4]\n",
    "trip_advisor_data[\"name_beg\"] = trip_advisor_data['Name'].str.strip().str[:4]\n",
    "trip_advisor_data = trip_advisor_data.drop_duplicates(subset = ['name_beg', 'add_beg'])\n",
    "trip_advisor_data = trip_advisor_data.drop(columns=['add_beg', 'name_beg'])\n",
    "\n",
    "#Drop entries that are not from Seattle\n",
    "trip_advisor_data = trip_advisor_data[trip_advisor_data['Address'].str.contains(\"Seattle\", na=False)]\n",
    "trip_advisor_data[\"Zip Code\"] = trip_advisor_data['Address'].str.strip().str.extract(r'(\\b981\\d{2}\\b)')\n",
    "\n",
    "trip_advisor_data = get_neighborhood(trip_advisor_data)\n",
    "\n",
    "#Export to csv\n",
    "trip_advisor_data.to_csv(os.path.join(data_folder, 'Trip_Advisor_Processed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Google Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all rows without ratings\n",
    "google_data = google_data_raw[google_data_raw['rating'].notna()]\n",
    "google_data = google_data_raw[google_data_raw['reviews'].notna()]\n",
    "\n",
    "#Drop irrelevant Columns\n",
    "google_data = google_data.drop(columns=['link', 'place_id'])\n",
    "\n",
    "#Rename columns to fit naming convention\n",
    "google_data = google_data.rename(columns={'name':'Name', \n",
    "                                              'reviews':'Num Reviews',\n",
    "                                              'categories':'Tags',\n",
    "                                               'main_category':'Main Tag',\n",
    "                                                'rating':'Rating',\n",
    "                                                'address':'Address'})\n",
    "\n",
    "#Drop (near) Duplicate entries\n",
    "google_data[\"add_beg\"] = google_data['Address'].str.strip().str[:15]\n",
    "google_data[\"name_beg\"] = google_data['Name'].str.strip().str[:15]\n",
    "google_data = google_data.drop_duplicates(subset = ['name_beg', 'add_beg'])\n",
    "google_data = google_data.drop(columns=['add_beg', 'name_beg'])\n",
    "\n",
    "#Drop entries that are not from Seattle\n",
    "google_data = google_data[google_data['Address'].str.contains(\"Seattle\", na=False)]\n",
    "google_data[\"Zip Code\"] = google_data['Address'].str.strip().str.extract(r'(\\b981\\d{2}\\b)')\n",
    "\n",
    "google_data = get_neighborhood(google_data)\n",
    "\n",
    "#Export to csv\n",
    "google_data.to_csv(os.path.join(data_folder, 'Google_Processed.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
