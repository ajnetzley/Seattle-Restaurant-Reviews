{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alex Netzley\n",
    "#2/18/2024\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the data\n",
    "data_folder = os.path.join(os.path.dirname(os.getcwd())+'/data/')\n",
    "#Read in Yelp Data\n",
    "yelp_data = pd.read_csv(os.path.join(data_folder, 'yelp_Processed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary EDA\n",
    "\n",
    "print(len(yelp_data))\n",
    "\n",
    "#Extract average number of reviews\n",
    "print(np.mean(yelp_data['Num Reviews']))\n",
    "print(np.mean(yelp_data['Rating'].astype('Float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the primary tag\n",
    "tags = yelp_data[\"Tags\"].replace('[\\[\\]\\\"\\' ]', '', regex=True)\n",
    "p_tags = []\n",
    "for row in tags:\n",
    "    p_tags.append(row.split(',')[0])\n",
    "\n",
    "yelp_data['Primary Tag'] = p_tags\n",
    "yelp_data.loc[yelp_data[\"Primary Tag\"] == 'SushiBars', 'Primary Tag'] = \"Sushi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_counts = (yelp_data['Primary Tag'].value_counts())\n",
    "cat_counts.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to restuarants with at least 50 Reviews (this remes)\n",
    "yelp_data = yelp_data[yelp_data['Num Reviews'] >=50]\n",
    "\n",
    "# Filter to Types with at least 20 entries\n",
    "filt_yelp = yelp_data[yelp_data['Primary Tag'].isin(cat_counts[cat_counts >= 20].index)]\n",
    "\n",
    "#Excluding all non-food restuarants\n",
    "exclude_list = ['Bakeries', 'Delis','SportsBars', 'DiveBars', 'IceCream&FrozenYogurt', 'Cafes', 'Pubs', 'CocktailBars', 'FastFood', 'Bars', 'Coffee&Tea', 'Donuts']\n",
    "\n",
    "filt_yelp = filt_yelp[~filt_yelp['Primary Tag'].isin(exclude_list)]\n",
    "\n",
    "\n",
    "cat_counts = (filt_yelp['Primary Tag'].value_counts())\n",
    "cat_counts.plot(kind = 'barh', figsize = (8, 8))\n",
    "\n",
    "#At this point we have 21 cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot average rating of these most common cuisines\n",
    "average_rating = (filt_yelp.groupby('Primary Tag')['Rating'].mean()).sort_values()#.tail(5)\n",
    "average_rating.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate SD of these most common cuisines\n",
    "std_rating = (filt_yelp.groupby('Primary Tag')['Rating'].std()).sort_values()#.tail(5)\n",
    "se_rating = std_rating/np.sqrt(cat_counts)\n",
    "avg_rating_upper = average_rating + 1.96*se_rating\n",
    "avg_rating_lower = average_rating - 1.96*se_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_analysis_df = pd.concat([average_rating, avg_rating_upper, avg_rating_lower, cat_counts], axis = 1)\n",
    "filtered_combined_analysis = combined_analysis_df[combined_analysis_df[\"Rating\"] > 3.93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(filtered_combined_analysis.index, \n",
    "             filtered_combined_analysis[\"Rating\"], \n",
    "             yerr = [filtered_combined_analysis[\"Rating\"] - filtered_combined_analysis[1], filtered_combined_analysis[0] - filtered_combined_analysis[\"Rating\"]],\n",
    "            fmt='o',\n",
    "            capsize=10,\n",
    "            linestyle='None' )\n",
    "plt.xticks(filtered_combined_analysis.index, filtered_combined_analysis.index)\n",
    "plt.xlabel(\"Cuisine\", labelpad=15)\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "\n",
    "counts = filtered_combined_analysis[\"count\"].apply(lambda x: f\"(n = {x})\")\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(filtered_combined_analysis.index[i], 3.773, count, ha='center')\n",
    "\n",
    "plt.title('Average Rating with 95% Confidence Interval for the Top 5 Cuisines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yelp_data_seafood = yelp_data[yelp_data['Yelp Tags'].str.contains(\"New\", na=False)]\n",
    "# plt.hist(yelp_data_seafood['Yelp Rating'].astype('Float32'))\n",
    "# plt.title('Histogram of Star Rating for New American Restaurants')\n",
    "# plt.xlabel('Star Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yelp_data_medi = filt_yelp[filt_yelp['Tags'].str.contains(\"Medi\", na=False)]\n",
    "# plt.hist(yelp_data_medi['Rating'].astype('Float32'))\n",
    "# plt.title('Distribution of Star Ratings for Yelp Restaurants')\n",
    "# plt.xlabel('Star Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "yelp_data_medi = filt_yelp[filt_yelp['Tags'].str.contains(\"Medi\", na=False)]\n",
    "medi = (yelp_data_medi['Rating']).to_numpy().astype(float)\n",
    "\n",
    "yelp_data_korean = filt_yelp[filt_yelp['Tags'].str.contains(\"Korean\", na=False)]\n",
    "korean = (yelp_data_korean['Rating']).to_numpy().astype(float)\n",
    "\n",
    "yelp_data_italian = filt_yelp[filt_yelp['Tags'].str.contains(\"Italian\", na=False)]\n",
    "italian = yelp_data_italian['Rating'].to_numpy().astype(float)\n",
    "\n",
    "yelp_data_sushi = filt_yelp[filt_yelp['Tags'].str.contains(\"Sushi\", na=False)]\n",
    "sushi = yelp_data_sushi['Rating'].to_numpy().astype(float)\n",
    "\n",
    "yelp_data_japanese = filt_yelp[filt_yelp['Tags'].str.contains(\"Japan\", na=False)]\n",
    "japanese = yelp_data_japanese['Rating'].astype('Float32').to_numpy().astype(float)\n",
    "\n",
    "t_stats = []\n",
    "p_values = []\n",
    "for opp in [korean, italian, sushi, japanese]:\n",
    "    t_stat, p_value = stats.ttest_ind(medi, opp, equal_var=False, alternative='greater')\n",
    "    t_stats.append(t_stat)\n",
    "    p_values.append(p_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DATA557",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
